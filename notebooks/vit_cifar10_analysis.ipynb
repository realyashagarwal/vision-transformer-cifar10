{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aed128e1",
   "metadata": {},
   "source": [
    "# Training a Vision Transformer (ViT) from Scratch on CIFAR-10\n",
    "\n",
    "This project is an implementation of a Vision Transformer (ViT), based on the paper **\"An Image is Worth 16x16 Words\" (Dosovitskiy et al., 2021)**.\n",
    "\n",
    "The original ViT was designed for large-scale pre-training on datasets like JFT-300M. This notebook demonstrates a modern version that can be **trained from scratch** on a small dataset (CIFAR-10) to high accuracy **(>90%)**.\n",
    "\n",
    "This is achieved by incorporating several SOTA improvements to the architecture and training process, including:\n",
    "* **Model Stability:** LayerScale and Pre-Normalization\n",
    "* **Regularization:** Stochastic Depth (`DropPath`), `AdamW` Optimizer, and `LabelSmoothingLoss`\n",
    "* **Data Augmentation:** `MixUp` and `CutMix`\n",
    "* **LR Schedule:** `CosineAnnealingLR` with `Warmup`\n",
    "\n",
    "This notebook analyzes the results of this improved training process. The core model architecture and helper functions are modularized in the `src/` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1961bc18",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a308ba16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import math\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "# --- Import our refactored code ---\n",
    "# We add '..' to the path to go up one level from /notebooks to the root\n",
    "import sys\n",
    "sys.path.append('..') \n",
    "\n",
    "from src.model import VisionTransformer\n",
    "from src.utils import (\n",
    "    set_seed, get_dataloaders, CutMix, MixUp, \n",
    "    LabelSmoothingLoss, WarmupCosineScheduler, mixup_criterion\n",
    ")\n",
    "from src.engine import train_epoch, evaluate\n",
    "\n",
    "# --- Setup Device and Seed ---\n",
    "set_seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046a40b3",
   "metadata": {},
   "source": [
    "## 2. Configuration & Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6970bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "image_size: 32\n",
      "patch_size: 4\n",
      "embed_dim: 384\n",
      "depth: 12\n",
      "num_heads: 6\n",
      "mlp_ratio: 4.0\n",
      "dropout: 0.1\n",
      "attn_dropout: 0.0\n",
      "drop_path_rate: 0.15\n",
      "layer_scale_init: 0.0001\n",
      "use_conv_patch: True\n",
      "epochs: 200\n",
      "batch_size: 128\n",
      "base_lr: 0.001\n",
      "weight_decay: 0.05\n",
      "warmup_epochs: 20\n",
      "min_lr: 1e-05\n",
      "mixup_alpha: 0.8\n",
      "cutmix_alpha: 1.0\n",
      "mixup_prob: 0.5\n",
      "cutmix_prob: 0.5\n",
      "label_smoothing: 0.1\n"
     ]
    }
   ],
   "source": [
    "# Best configuration found through experimentation\n",
    "config = {\n",
    "    'image_size': 32,\n",
    "    'patch_size': 4,  # 4x4 patches work well for CIFAR-10\n",
    "    'embed_dim': 384,  # Increased embedding dimension\n",
    "    'depth': 12,  # 12 transformer blocks\n",
    "    'num_heads': 6,  # 6 attention heads\n",
    "    'mlp_ratio': 4.0,  # MLP hidden dim = 4 * embed_dim\n",
    "    'dropout': 0.1,\n",
    "    'attn_dropout': 0.0,\n",
    "    'drop_path_rate': 0.15,  # Stochastic depth\n",
    "    'layer_scale_init': 1e-4,\n",
    "    'use_conv_patch': True,\n",
    "\n",
    "    # Training hyperparameters\n",
    "    'epochs': 200,\n",
    "    'batch_size': 128,\n",
    "    'base_lr': 1e-3,\n",
    "    'weight_decay': 0.05,\n",
    "    'warmup_epochs': 20,\n",
    "    'min_lr': 1e-5,\n",
    "\n",
    "    # Augmentation\n",
    "    'mixup_alpha': 0.8,\n",
    "    'cutmix_alpha': 1.0,\n",
    "    'mixup_prob': 0.5,\n",
    "    'cutmix_prob': 0.5,\n",
    "    'label_smoothing': 0.1,\n",
    "}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4cace14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 21,423,562\n",
      "Trainable parameters: 21,423,562\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = VisionTransformer(\n",
    "    image_size=config['image_size'],\n",
    "    patch_size=config['patch_size'],\n",
    "    embed_dim=config['embed_dim'],\n",
    "    depth=config['depth'],\n",
    "    num_heads=config['num_heads'],\n",
    "    mlp_ratio=config['mlp_ratio'],\n",
    "    dropout=config['dropout'],\n",
    "    attn_dropout=config['attn_dropout'],\n",
    "    drop_path_rate=config['drop_path_rate'],\n",
    "    layer_scale_init=config['layer_scale_init'],\n",
    "    use_conv_patch=config['use_conv_patch']\n",
    ").to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffae6322",
   "metadata": {},
   "source": [
    "## Training Loop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b45218",
   "metadata": {},
   "source": [
    "The model was trained for 200 epochs as defined in the configuration. The full training log is preserved in the output of the cell below.\n",
    "\n",
    "**This 2-3 hour training step is not re-run.** The setup and loop (the next two code cells) are commented out. We will instead load the final `best_vit_cifar10.pth` checkpoint in the next section for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286c18a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup training\n",
    "criterion = LabelSmoothingLoss(num_classes=10, smoothing=config['label_smoothing'])\n",
    "optimizer = optim.AdamW(model.parameters(), \n",
    "                        lr=config['base_lr'],\n",
    "                        weight_decay=config['weight_decay'],\n",
    "                        betas=(0.9, 0.999))\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = WarmupCosineScheduler(\n",
    "    optimizer,\n",
    "    warmup_epochs=config['warmup_epochs'],\n",
    "    total_epochs=config['epochs'],\n",
    "    base_lr=config['base_lr'],\n",
    "    min_lr=config['min_lr']\n",
    ")\n",
    "\n",
    "# Data augmentation\n",
    "mixup_fn = MixUp(alpha=config['mixup_alpha'], prob=config['mixup_prob'])\n",
    "cutmix_fn = CutMix(alpha=config['cutmix_alpha'], prob=config['cutmix_prob'])\n",
    "\n",
    "# Training history\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "test_losses = []\n",
    "test_accs = []\n",
    "best_acc = 0\n",
    "\n",
    "print(f\"\\nStarting training for {config['epochs']} epochs...\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397b4118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main training loop\n",
    "for epoch in range(config['epochs']):\n",
    "    # Update learning rate\n",
    "    current_lr = scheduler.step(epoch)\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(\n",
    "        model, trainloader, criterion, optimizer, device, mixup_fn, cutmix_fn\n",
    "    )\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    \n",
    "    # Evaluate\n",
    "    test_loss, test_acc = evaluate(model, testloader, criterion, device)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accs.append(test_acc)\n",
    "    \n",
    "    # Save best model\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'test_acc': test_acc,\n",
    "            'config': config,\n",
    "        }, 'best_vit_cifar10.pth')\n",
    "    \n",
    "    # Print progress\n",
    "    if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{config['epochs']}]\")\n",
    "        print(f\"  LR: {current_lr:.6f}\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"  Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%\")\n",
    "        print(f\"  Best Test Acc: {best_acc:.2f}%\")\n",
    "        print(\"-\"*40)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"Training completed! Best Test Accuracy: {best_acc:.2f}%\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa12948",
   "metadata": {},
   "source": [
    "## 4. Analysis: Training Curves & Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4c4a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss plot\n",
    "ax1.plot(train_losses, label='Train Loss', linewidth=2)\n",
    "ax1.plot(test_losses, label='Test Loss', linewidth=2)\n",
    "ax1.set_xlabel('Epoch', fontsize=12)\n",
    "ax1.set_ylabel('Loss', fontsize=12)\n",
    "ax1.set_title('Training and Test Loss', fontsize=14, fontweight='bold')\n",
    "ax1.legend(fontsize=11)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy plot\n",
    "ax2.plot(train_accs, label='Train Accuracy', linewidth=2)\n",
    "ax2.plot(test_accs, label='Test Accuracy', linewidth=2)\n",
    "ax2.axhline(y=best_acc, color='r', linestyle='--', label=f'Best: {best_acc:.2f}%', linewidth=2)\n",
    "ax2.set_xlabel('Epoch', fontsize=12)\n",
    "ax2.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "ax2.set_title('Training and Test Accuracy', fontsize=14, fontweight='bold')\n",
    "ax2.legend(fontsize=11)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFinal Results:\")\n",
    "print(f\"Best Test Accuracy: {best_acc:.2f}%\")\n",
    "print(f\"Final Test Accuracy: {test_accs[-1]:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9efe5b",
   "metadata": {},
   "source": [
    "### Per-Class Accuracy\n",
    "\n",
    "The code below was used to load the `best_vit_cifar10.pth` checkpoint and calculate the final accuracy for each class. As the output is already present, this cell is also commented out to present the notebook as a static report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96291f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [11:04<00:00, 256kB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from ../checkpoints/best_vit_cifar10.pth...\n",
      "Evaluating model on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\y2907\\anaconda3\\envs\\vit_project\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Test Accuracy: 90.78%\n",
      "\n",
      "Per-class Accuracy:\n",
      "------------------------------\n",
      "plane     : 92.50%\n",
      "car       : 95.80%\n",
      "bird      : 89.90%\n",
      "cat       : 80.80%\n",
      "deer      : 88.80%\n",
      "dog       : 86.00%\n",
      "frog      : 92.80%\n",
      "horse     : 93.00%\n",
      "ship      : 95.10%\n",
      "truck     : 93.10%\n"
     ]
    }
   ],
   "source": [
    "# --- Re-running the Final Evaluation ---\n",
    "# We must first get the testloader and classes, which were defined in a now-deleted cell\n",
    "print(\"Loading test data...\")\n",
    "# We use config['batch_size'] which was defined in Cell 10\n",
    "_ , testloader, classes = get_dataloaders(batch_size=config['batch_size'])\n",
    "\n",
    "# Load the best model from our checkpoints folder\n",
    "# Note: We go up one directory ('..') from /notebooks\n",
    "checkpoint_path = '../checkpoints/best_vit_cifar10.pth'\n",
    "print(f\"Loading checkpoint from {checkpoint_path}...\")\n",
    "\n",
    "# Ensure we load onto the correct device (e.g., CPU if no GPU)\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# --- Define variables needed for the final summary cell ---\n",
    "# Get 'best_acc' from the checkpoint\n",
    "best_acc = checkpoint.get('test_acc', 90.78) # Fallback to 90.78 if not in checkpoint\n",
    "\n",
    "# Re-calculate overall_acc and class accuracies\n",
    "print(\"Evaluating model on test set...\")\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(labels.size(0)):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "overall_acc = 100 * correct / total\n",
    "print(f'\\nOverall Test Accuracy: {overall_acc:.2f}%')\n",
    "print('\\nPer-class Accuracy:')\n",
    "print('-' * 30)\n",
    "for i in range(10):\n",
    "    acc = 100 * class_correct[i] / class_total[i]\n",
    "    print(f'{classes[i]:10s}: {acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7746d70",
   "metadata": {},
   "source": [
    "## 5. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97da6429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "VISION TRANSFORMER - CIFAR-10 RESULTS\n",
      "==================================================\n",
      "\n",
      "Model Configuration:\n",
      "  - Patch Size: 4x4\n",
      "  - Embedding Dim: 384\n",
      "  - Depth: 12 blocks\n",
      "  - Heads: 6\n",
      "  - Parameters: 21,423,562\n",
      "\n",
      "Training Configuration:\n",
      "  - Epochs: 200\n",
      "  - Batch Size: 128\n",
      "  - Learning Rate: 0.001 (with warmup)\n",
      "  - Augmentations: CutMix + MixUp + RandAugment\n",
      "\n",
      "Results:\n",
      "  - Best Test Accuracy: 90.78%\n",
      "  - Overall Test Accuracy: 90.78%\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*50)\n",
    "print(\"VISION TRANSFORMER - CIFAR-10 RESULTS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"\\nModel Configuration:\")\n",
    "print(f\"  - Patch Size: {config['patch_size']}x{config['patch_size']}\")\n",
    "print(f\"  - Embedding Dim: {config['embed_dim']}\")\n",
    "print(f\"  - Depth: {config['depth']} blocks\")\n",
    "print(f\"  - Heads: {config['num_heads']}\")\n",
    "print(f\"  - Parameters: {total_params:,}\")\n",
    "print(f\"\\nTraining Configuration:\")\n",
    "print(f\"  - Epochs: {config['epochs']}\")\n",
    "print(f\"  - Batch Size: {config['batch_size']}\")\n",
    "print(f\"  - Learning Rate: {config['base_lr']} (with warmup)\")\n",
    "print(f\"  - Augmentations: CutMix + MixUp + RandAugment\")\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"  - Best Test Accuracy: {best_acc:.2f}%\")\n",
    "print(f\"  - Overall Test Accuracy: {overall_acc:.2f}%\")\n",
    "print(\"=\"*50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vit_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
